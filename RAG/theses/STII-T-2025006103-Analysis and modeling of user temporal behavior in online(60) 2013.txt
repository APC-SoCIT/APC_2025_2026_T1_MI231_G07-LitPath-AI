Analysis and Modeling of User Temporal Behavior in Online Communication Using a Doubly Stochastic Process

AIVIN V. SOLATORIO

University of the Philippines Diliman

Master of Science in Physics

April 2013

ABSTRACT

We propose a model to explain message posting of users in Twitter. Our model,
the Co-timescale Cox Process (CTCP) model, is based on the idea of timescales
and Cox Process, a doubly stochastic process. We suggest that by considering
only the disparity in the timescale, i.e., short and long timescales, of the inter-
event time between tweets in our model, we will be able to predict the form of the empirical inter-event time distribution of user in Twitter. We provide a new perspective in modeling human behavior. We avoided to
explicitly incorporate factors that are intuitive to influence human behavior in
our model. This is in contrast with traditional modeling techniques for human
behavior. We demonstrate that more insights can be inferred by not explicitly in-
corporating such specific and intuitive behavioral attributes, e.g., sleeping pattern, in the model. We define a truncated power law model as the null model. This null model
serves as the baseline of the performance of our proposed model. Since empirical
data have been frequently reported to obey power law behavior, we use the trun-
cated power law model to evaluate whether, at the individual level, the power law model is still an appropriate explanation for human behavior. Our results show that the CTCP model is able to explain 52.08% of users in the
dataset used. In contrast, only 10.47% of the users are explained by the truncated power law. We also considered the performance of both models across different types of user classes based on activity level. We found that most users in the high activity
user class cannot be explained by both the CTCP model and the truncated power
law model. This suggests that other mechanisms govern most users in this class.
Based on the four classes of users, we found that the models perform best in the low activity user class. Lastly, we show that the CTCP model explains exclusively a set of individ-
uals that do not possess seasonal behavior and power law behavior. We would
intuitively think that it seems impossible for users to have no seasonal behavior
depicted in their temporal pattern since we all sleep. The absence of a seasonal
signature can possibly be attributed to Twitter influenced shifts in sleeping pat-
terns. Various ways of accessing Twitter allow users to post tweets almost anytime
which can also be a possible reason for the lack of seasonal signature for some of
the users. These results give us insights as to how multiple ways of connecting to
Twitter as well as how an individual uses the system itself induce change in an
individual’s behavior.

PACS: 05.10.-a (Statistical physics and nonlinear dynamic), 02.50.-r (Statistics),
89.75.-k (Complex systems), 05.10.Gg (Stochastic models in statistical physics and
nonlinear dynamics), 89.20.-a (Interdisciplinary applications of physics)

Chapter 1
Introduction

With the availability of large datasets, empirical patterns in the temporal
behavior, primarily a power law, have been found for human activities. The
waiting time [1] in letter correspondence, inter-event time in SMS communication
2,3], letter correspondence {4], e-mail sending [5,6], and online activities [7,8], as
well as inter-arrival times in document printing [9] are examples of these temporal
behavior. However, empirical data alone cannot provide us with a clear insight
as to how such behavior emerges. To explain such phenomenon, one should infer,
identify sequence of logical mechanisms, and develop a sound model that would
agree with real-world data.

For the case of human behavior, various factors may affect how one performs
an activity. Sleeping patterns and seasonality are two concepts which seem to
intuitively influence human behavior. This is mainly because we all need to sleep.
Most of our activities are also seasonal or periodic such as going to school, work,
eating, etc. The interest of an individual in a specific task also affects how an
individual behaves. To illustrate this, an individual usually prefers to engage
longer in an activity that he/she likes as compared to an activity that he/she has
less interest on. Priority of a certain activity also plays an important role in the
manner an individual accomplishes a set of tasks. The impact of a task’s priority
on human behavior is best described by a scenario wherein a person having many
tasks at hand, prioritizes them according to some order, i.c., the task with highest
priority is executed first. Deviations in task execution from this priority list can
be attributed to random decision making of an individual.

The possible effects of sleeping pattern and seasonality, interest, and priority

on human behavior have been proven by testing models incorporating these con-

cepts against empirical data and simulation results. For instance, the cascaded
Poisson process model [10] by Malmgren, et al., showed that sleeping pattern and
seasonality indeed affect human activity. An e-mail dataset was used by them to
conclude that: e-mail sending can be described by an interplay of two mechanisms.
The first mechanism explicitly incorporates the sleeping pattern of users and their
tendency to perform seasonal tasks. They used the inhomogeneous Poisson pro-
cess as the generator of events for the first mechanism with the rate having the

form,

p(t +T) = Nupalt)Pu(t)- (14)
where T is the period of the process which they set to one week, N, is the number
of active intervals in a week, pg(t) is the hourly sending probability and p,,(t)
is the daily sending probability. In contrast, they used the homogeneous Poisson
process to describe events in the second mechanism. The second mechanism simply
suggests that a user performs e-mail sending at a relatively constant rate.

‘The effect of interest in human behavior [11,12] and the emergence of power law
was discussed by Shang, et al. [12]. The authors proposed a mathematical model
describing the system of human activity with explicit dependence on interest.
Interest has been represented in their model as the likelihood that an individual

will repeatedly do an activity. They quantified interest as a probability

l+a(t-t)’
that is dependent on the difference between the current time ¢ and ?’ - the last

x(t) = (1.2)

time when the individual engaged in the activity . This quantity for interest has
a tunable parameter a that can be interpreted as an intensity scaling parameter
such that when it is large, the interest of the individual is lower as compared when.
the value for a is low .

Lastly, the Barabasi model [5] explains the emergence of a heavy-tail (power
law) pattern from priority queuing. The Barabasi model considers a queue that
can accommodate L number of tasks with different priorities. The execution of a
task is specified such that events will be executed based on their priority with a
probability of p, while a task will be executed regardless of its associated priority
with a probability (1—p). This priority model yields a heavy-tailed distribution of

task waiting time. The waiting time is defined as the time needed by a task to wait
in the queue before it is executed. This model was successful when tested against
an e-mail dataset. This mechanism has been a central model for succeeding works
done on other types of human activities [1].

We can observe that the models introduced above were all based on intuitive

assumptions regarding human activities. Truly, we can expect that a model that is
based on human behavioral attributes that are already very evident will outstand-
ingly explain the behavior of individuals. Although, this kind of modeling is more
of a validation of the obvious or intuitive factors that govern human behavior. As
an example, the model of Malmgren, et al., [10] considering sleeping pattern and
seasonality effects as the factors that govern human behavior have successfully
modeled all but one of the users in the dataset they used. At first sight, this
result seems to be remarkable, yet after thinking about it, their model really just
tells us what we already know, i.e., humans tend to perform in a seasonal manner
and that sleeping affects how we behave. With these kinds of models, the level
of inference that we can make regarding the mechanisms on how humans behave
is limited to the obvious factors that have been deliberately incorporated in the
model design.

We find a need for a new approach in modeling human behavior after con-
sidering the points above. Here, we present a different perspective in modeling
human behavior. We circumvent the process of incorporating very specific human
behavioral attributes in our model. Instead, we based our model on the concept
of timescales. We considered that users can be modeled by considering only the
disparity in the timescale at which they perform activities, i.e., short and long
timescales, and the concept of co-timescale events. A caveat though is that by
not incorporating specific behavioral attributes in our model, our model may not
be able to explain users having those attributes. Furthermore, because our model
considers only the disparity in the timescale of events instead of a specific behav-
ioral attribute, one may think that our model will fail to explain the behavior of
user. Yet, our results tell otherwise.

This work consists of: the creation of a model that is based on anew perspective
of modeling; and the validation of the proposed model by comparing its predictions
against an empirical dataset; and comparison of the performance of the model and

that of a truncated power law model.

The remaining part of this thesis is outlined as follows. In Chapter 2, we
will provide the definitions and concepts that will be used throughout this thesis.
Next, Chapter 3 will contain the methodology of our work. We will formally
define our model in this chapter together with the steps taken to implement it.
Chapter 4 encapsulates the result of our work together with the discussion of their

implications. Lastly, we will conclude this work in Chapter 5.

Chapter 2
Definition of Terms and Concepts

In this section, we define the terms and concepts that will be used in the rest of
this thesis. We will tackle first the relevant concepts and ideas in Twitter where
our data was collected. Next, we will provide definition to general terms that
will be used in the formulation of our model. Then, the statistical terminologies
will be defined. Lastly, the relevant statistical analyses used in the thesis will be
discussed.

2.1 Twitter

Twitter [13] is both a social networking site and a micro-blogging site. Twitter
consists of millions of users worldwide. It has a feature allowing users to “follow”
another entity in Twitter which gives rise to its networked structure. Users have
the option to set their account as private barring unauthorized individuals from
accessing the user’s profile. On the other hand, users with their profiles set to
public allow other Twitter users to see their profile together with the messages

they post.

Tweet, User Timeline and Twitter API

As a micro blogging site, Twitter users can post “tweets”. A “tweet” is the
terminology referring to messages posted by a user. Tweets can have at most 140
characters each.

Each user in Twitter has a timeline. This timeline consists of records of user’s
activities. All tweets made by a user together with mentions - messages from its

followers, are cataloged in the timeline. Users are also able to re-tweet “tweets”

‘Tweets

Aivin Solatorio
‘1m excited by athe 5 gadget giveaways from yugatech and

smeyberzone here ~ yugatech conveoniestsleonte 1220 AM - 3 Dec 12

yan Reply @ Det Fa
Philosophers quotes N
“The law alvays mts every pover& gies, ~ David Hume bi
Aivin Solatorio
Hoypaviela jazzybat_baracoma cheabundo _janeypoo
abet? cheesepops CidyGreta noma na me =)
1p GMANews N

GEIS. Quezon cry: mayor Herbert Bautista announces cancelation of
SENS, sssesin lt Levels un FRIDAY UG 0| sansa wa
saree

‘Wes Gonzalez N
Tobe abe to use th saving people, some rescuers
resoed ots. age anvplOCACRIL EY

Figure 2.1: A screenshot of a portion of a user timeline. This portion of the timeline
depicts five messages posted by the user. Note that each of the tweets in the timeline
has a corresponding timestamp. These timestamps indicate the time at which a tweet
was posted.

from the users they follow as well as public users. Tweets in the timeline have
timestamps corresponding to the time when these messages were posted.

The Twitter API (Application Programming Interface) [14] is a an interface
designed for a third party to access the contents of Twitter. The Twitter API can
be accessed using different programs. As an example, an individual may be able
to access the content of a user timeline from Python - a programming language.
Furthermore, one may also be able to post tweets via the API.

2.2 Definition of Terms

Timescale, Co-timescale Events, and Train of Events

We define the timescale as a relative measure of how long an event is per-
formed or how long two events are separated in time. In our work, we will be
using two types of timescales. These timescales are the short timescale and long

timescale. The quantitative measure in classifying whether an event belongs to a

specific timescale will be presented in our methodology.

Given a set of events, we define the co-timescale events as events classified
according to the same timescale. Hence we will be dealing with short co-timescale
events as well as with long co-timescale events.

A train of events refers to consecutive events in a time series. Specifically,
a train of short (long) co-timescale events consists of consecutive events that are
classified as short (long) timescale.

Inter-event Time

Given a time series of events, the inter-event time is defined as the difference
in the time between two consecutive events in the time series. Mathematically, let
{t1, te, ta, ...,tn} be a time series of events. Then, the inter-event time At is given
by

Ati = tina — ty (2.1)

where the index é corresponds to the i‘ event in the time series. The inter-event
time is also illustrated in Fig. 2.2.

Illustration of Interevent Time Calculation

Interevent time: At; = tu - t

Figure 2.2: A graphical representation of inter-event time for a given sequence of events.
Assume that events are represented by the vertical arrows at a specific time t;. The
separation between events is the inter-event time pictured as the horizontal arrows.

Stochastic or Random Variable

A stochastic variable is a term referring to the outcome of an experiment,

although its value is undetermined until the experiment is conducted [15]. This

suggests that each of the possible values of a stochastic variable may not have an
equal chance of occurrence in an experiment. As an illustration, one may consider
a radioactive material emitting f-particles. Because the emission of B-particles
happens randomly we can not be sure what the number of emitted particles will
be before the experiment. Hence, we can define the number of emitted B-particles
at a prescribed time interval as a stochastic variable X. This stochastic variable
X can take any natural number as its value. Although, the values that X can take
do not necessarily have the same probability of being observed in an experiment.

Stochastic variables can be discrete or continuous. A discrete stochastic
variable is associated with experiments whose possible outcome consists of discrete
values. As an example, we can again consider the radioactive material emitting
B-particles. The stochastic variable X for that experiment is a discrete stochastic
variable since the possible value of X is any of the natural numbers, eg., {0,
1, 2, 3, ...}. In contrast, the continuous stochastic variable Y is associated with
experiments whose possible outcome comes from a continuous range of values. We
can take, for example, a system containing many grains of rice. If we perform an
experiment of taking the weight of a grain, then, a grain’s weight is a continuous
stochastic variable since the measured weight of a grain can take any positive real
value, ie., Y € (0,00).

Probability Mass Function and Probability Density Function

Consider a discrete stochastic variable X. Let {x1, 2,23, ..., 2} be the set of
the possible values of X. Also, let {p1,p2,Ps,---»Pn} be the set of probabilities
corresponding to the possible values of X. The probability mass function of a
discrete stochastic variable X is defined as the mapping of the outcome z; to its
probability p; [15,16]. We define the expression for the probability mass function
as

P(X = 21) =P, (2.2)

which means that the probability of the stochastic variable X taking the value of

2; is equal to p;.
For the case of a continuous stochastic variable Y, we can extend the rela-
tions defined for the discrete stochastic variable. Here, we define the probability

Probability Mass Function Probability Density Function

(Geometric Distribution) (Exponential Distribution)
0.14 i i

oz AX =2)=(-p'p : Pla) =e
o.10

0.08

A{X=2)

0.06

0.04

0.02

0.00

Figure 2.3: Here, we illustrate the a) probability mass function and the b) probability
density function for the geometric and exponential distributions, respectively. Note
that the probability mass function of the geometric distribution is defined only in the
domain {1, 2, 3, ...}, hence, discrete. If we observe the probability density function
of the exponential distribution, we see that it can take a value in the domain (0, 00),
hence, continuous. The equation in the figures represents the functional form of the
corresponding distribution.

density function P(y) [15,16] for the stochastic variable Y as

P(asY¥ <b)= [ ” Play. (2.3)

This is interpreted as the probability that the stochastic variable Y will take a
value between a and b. This probability is equal to the integral of the probability
density function P(y) in the given range.

Cumulative Distribution Function and Complementary Cumulative Dis-
tribution Function

The cumulative distribution function F(z) [15,16] for a stochastic variable
X is defined as:

F(a) = P(X <2). (2.4)

This means that the value associated to F(z) is equal to the probability that the
stochastic variable X is less than or equal to z. Alternatively, we may define the

cumulative distribution function as:


Fe@)= f° Pway (2.5)

where P(y) corresponds to the probability mass (density) function of a discrete

(continuous) stochastic variable and min is the lower support of the probability
mass (density) function.

The complementary cumulative distribution function is defined as
1- F(a).

The Power Law Model

In the field of complex systems, many stochastic variables have been discovered
to obey a power law behavior [17]. This behavior, for discrete integral valued

stochastic variable, is characterized by the probability mass function

P(z)= {

where a and 2min are the parameters of the distribution. The value for « must be

(26)

greater than one while «nin is the lower bound of the distribution. Note that ¢ is
the Hurwitz zeta function defined as:

(amin) = J (1+ nin) ~* (2.7)

=0
For the case of continuous stochastic variables, the power law behavior takes
the form:

Pe) = ( as ) ~ (2.8)

with the parameters a and Zmin taking the same role as in the discrete case.
This distribution has been used to model stochastic variables in complex sys-
tems such as earthquake inter-event times.

The Truncated Power Law Model

Despite the numerous works showing that a “pure” power law, as defined in
Eq. 2.6 and Eq. 2.8, is able to capture the distribution of stochastic variables
in complex systems, the usage of power law in modeling faces some challenges.

One of which is the scarcity of available empirical data in the tail part of the
distribution. This might be due to limitations in the data gathering.

One of the alternative models for a power law is the truncated power law
model [18-22]. This model specifically incorporates the fact that the observation
in the tail of the distribution must decay faster as compared with the power law.
This is done by truncating the power law distribution using an exponential tail.
The probability distribution function of the truncated power law is defined as:

trlent rma

~ T(0, 2)

where Tmin and Tmaz ate parameters of the distribution. The value of Tmin must

P(t) (2.9)

be greater than zero. Note that I’ is the upper incomplete gamma function with
the form:

T(s,z) f tle~tdt (2.10)

The Geometric Distribution

Assume a toss coin experiment. Consider that a toss landing in head is a
success event while that of a tail is a failed event. The distribution describing the
discrete stochastic variable X associated with the number of tosses it takes before
a success occurs is given by the geometric distribution [16]. The geometric
distribution is given by,

P(X =t)=(1-p)'"p (2.11)

where pis the probability that a success event will occur, (1—p) is the probability
of a failed event and t € {1,2,3,...} is the possible value of X.

Median and Interquartile Range

In statistics, given a set of data D, we can define various metrics that will
summarize the entire data. The mean of D and its standard deviation are the
common metrics used to describe a data. The mean provides a measure of the
data’s central value while the standard deviation gives the spread of the data.
Yet, the mean and the standard deviation, when used blindly, lead to problems.
This is because the mean and the standard deviation are metrics which receive a

ll

significant effect from outliers in the data. As an alternative, we will be using the
median and the interquartile range as the descriptors of the data in our work.
The median value 2 (16] of a data is defined as:

afl
peF (3) (2.12)

where F-! is the inverse of the cumulative distribution function of the data. This
relation also means that ys is the value which divides the data equally into its
upper and lower values. To demonstrate how ys is evaluated, assume a data given
by {1, 4, 3, 6, 9}. The median p for this data is equal to 4 because when the data
is sorted, {1, 3, 4, 6, 9}, the value of 4 divides the data equally into its lower and
upper half,

The interquartile range on the other hand is a relatively robust descriptor of
the data’s dispersion. The interquartile range [16] is defined as:

IQR = F-! (3) -F (3) (2.13)

where F" is the inverse of the cumulative distribution function of the data. The
expression F-1 (3) refers to the 3° quartile of the data and F-1 (1) is the 1%
quartile of the data.

We illustrate the definition of the median and the interquartile range in Fig. 2.4.

Empirical and Synthetic Data

The term empirical data refers to the set of data obtained from actual obser-
vation of events in the real world (23]. In contrast, synthetic data refers to a set
of data generated from a specified model [24]. This model may be a deterministic
or a stochastic model.

Null Model

In cases where a model is being proposed for an empirical data, it is a sound
practice to define a null model [25] that is qualified based on physical heuristic
arguments as an alternative model to the model being introduced. Essentially, the
null model will serve as a benchmark for the performance of the proposed model
in explaining the given data.


0.0
O30 -20 -10 0 10 20 30

x

Figure 2.4: Here, we show the definition of the median (1) and the interquartile range
(IQR) graphically. The median value for this distribution is the value pointed by the
red line and annotated as yu. This value corresponds to the point where the cumulative
distribution function is equal to 0.5. Furthermore, the IQR is illustrated in the figure as.
the black horizontal line annotated as IQR which is bounded by the 1* and 3° quartiles
of the cumulative distribution function.

2.3 Stochastic Processes

We define a stochastic process (temporal) as a process whose event’s occur-
rence is random [15,26]. As an example, we may consider a faucet where drops
of water are falling from it. If we consider the instance at which a drop of water
reaches the floor as an event, then, we can assume that the sequence of events
in this case is governed by a stochastic process. Furthermore, we may assign
the inter-event time of this process as a stochastic variable. This means that a
stochastic process is a sequence of events whose separation in time is given by @

stochastic variable.

2.3.1 Poisson Process

A specific case of a stochastic process is called the Poisson process [26]. In
the Poisson process, the stochastic variable for the inter-event time comes from

the exponential distribution with probability density function given by,

P(t)=de™, (2.14)


where ) is called the rate parameter. The rate parameter specifies the rate at
which an event will occur. The Poisson process is used to model various stochastic

systems such as the emission of radioactive particles.

2.3.2 Cox Process

The Cox process [27], also known as a doubly stochastic Poisson process, is ©
generalization of the Poisson process. Whereas a Poisson process is characterized
by a constant rate parameter A, the Cox process is characterized by a distribution
of rates P(A).

Given a distribution of rates P(A), the Cox process defines a sequence of events
as follows:

where ¢; is the time at which the i** event occurs after the (i—1)"* event. The value
of t; comes from a stochastic variable X drawn from the exponential distribution
characterized by the rate parameter \;. Although, 4; itself is a stochastic variable
drawn from a distribution of rates P(A).

2.4 Goodness-of-fit

We define a method called a goodness-of-fit [28] evaluation as the method for
testing the validity of a model against a given data. Assume, for example, the sys-
tem consisting of a radioactive material emitting B-particles. In subsection 2.3.1,
we have suggested that the process of radioactive emission can be considered as a
Poisson process. Hence, the Poisson process is a model for radioactive emission.
Suppose further that we have performed an actual experiment wherein we mea-
sured the time between emission of f-particles. Thus, we have a set of data for
the stochastic variable representing the time between emissions. Ultimately, the
answer to the question: “Does the model (Poisson process) accurately represent
the empirical data (observation)?”, is provided by the goodness-of-fit of the model
to the empirical data.

Kolmogorov-Smirnov Statistic
In statistical analysis, the equality of distributions can be evaluated by us-


ing some defined statistical measures for equality. An example of such equality
measure is the Kolmogorov-Smirnov (KS) statistic or KS test [28].

The KS test for equality of distributions directly compares two distributions
without any given parameters, hence, it is a nonparametric test. It is also a distri-
bution independent statistic since it measures the equality of a given distribution
without the use of the functional form of the distribution. Instead, the KS-test
measures the absolute distance between the distributions being compared. The
KS statistic K is defined as:

K = sup,(|Fi(z) - F(2)| (2.16)

where F,(z) and F,(z) are the cumulative distribution functions for the two sets of
data denoted by D, and D2 whose distributions are being evaluated for equality.
We illustrate the KS-test graphically in Fig. 2.5.

1.0
=a
e 6. Di
08 ‘
’
?
=F 06 K
vi Pe
s ¢
X04 j
?
0.2 ?
dj
a
0.06 10 20 30 40 50

zr

Figure 2.5: The definition for the Kolmogorov-Smirnov statistic K is illustrated in this
figure. Given the cumulative distribution functions for the two sets of data D; and D2,
the KS statistic is defined as the maximal distance between the two functions. The KS
statistic for this two distributions is illustrated by the vertical red line and annotated
as K.

Monte Carlo Hypothesis Testing and p-value

In modeling a system, it is customary to know whether the model agrees with
the empirical data. Usually, one performs a goodness-of-fit technique to measure


how well the model fits the empirical data. One is the Monte Carlo hypothesis
testing (25,29, 30].

Assume that you have an empirical data D that you want to model using the
model .#@. The purpose of the Monte Carlo hypothesis testing is to provide an
answer to the question: Is # a viable model to the given dataset D? The answer
to this question is quantified by a p-value. The p-value gives the probability that
the model provides a good fit to the data. As a rule of thumb, a p— value > 0.05
suggests that the model cannot be rejected as a mechanism for the system (the
model is a plausible model for the data).

The method of Monte Carlo hypothesis testing is outlined in the following
steps:

1. Estimate the best parameters of the model .@ from the data D.

2. Take an equality statistic based from some equality measure, such as the K
statistic for KS test, to evaluate the equality of the model prediction and
that of the empirical data. Denote this statistic value as Ks.

3. Generate an ensemble {D,} of size N, where D, are synthetic datasets gen-
erated from the model with the best fit to the data.

4, Treat each of the synthetic dataset in the same manner as an empirical data.
Meaning, each synthetic dataset will be modeled as well by -@. Therefore,
estimate the best parameters of the model from the synthetic data.

5. As with the empirical data, take an equality statistic based from some equal-
ity measure, such as the K statistic for KS test, to evaluate the equality of
the model prediction and that of the synthetic data. Denote these statistic
values as K,,j, where j = 1,2,3,...,.N.

6. Lastly, evaluate the p-value of the model .@ for data D by:

p-value = Pr(|Kz — (Kz)| > |Ks — (Ko)|)- (2.17)


The precision of the p-value is related to the size of the ensemble as given by the

following relation:

precision = + (2.18)

Chapter 3
Methodology

In this chapter we will first discuss the empirical data collection from Twitter.
Next, we will be formally defining our model. Lastly, we will discuss the methods

used to analyze the model.

3.1 Twitter Dataset
3.1.1 Data Collection

We collected data from Twitter using its API. We performed a random sam-
pling method in choosing which users to consider with a filter imposed such that
no private accounts will be included in the data. Again, using the Twitter API,
after gathering the list of users, we collected the corresponding timeline of a user.
A limitation, though, is that for users with more than 3,200 tweets in their time-
line, only the latest 3,200 tweets will be allowed by the API to be collected. The
collection procedure started in Sept. 3, 2012 up to Oct. 20, 2012 with ~198,000
users collected.

3.1.2 Processing of User Timeline

As illustrated in Fig. 2.1, the user timeline consists of tweets posted by a user
with an associated timestamp. The timestamp of a tweet has a resolution of one
second. For each user, we take the time series of tweets by taking the value of the
timestamps in the user timeline. The corresponding inter-event time sequence of

the time series is then evaluated.

3.1.3 Working Dataset Generation

After the inter-event time sequence of tweets from a user’s timeline has been
obtained, we check for users that will be included in our working dataset. We
impose that a user must have at least 50 inter-event times in its timeline for it to
be included in our working dataset. This filtering part of the work is performed for
statistical purposes since users with small number of activities are likely to have
false-positive results in the statistical tests. We store the qualified inter-event
time sequence and will be used in the model. The number of users amounted to
141,754.

3.2 Empirical Model
3.2.1 Model Definition

We propose a model .#/, which we refer to as the co-timescale Cox process
(CTCP), to explain tweet posting in Twitter. Our model is a stochastic process
for the sequence of events corresponding to the tweets of a user. This model
depends on the notion of different timescales of events performed by a user, i.e.,
short and long timescales.

To define the model, let k € [s, l], where s is associated with the short timescale
events and J is associated with the long timescale events. Assume that the proba-
bility distributions P(.,) are defined. Furthermore, let Nj, be stochastic variables
corresponding to the number of events in a k co-timescale train. The value for
N, is assumed to be defined by the geometric distribution with parameter p = px.
Now, we introduce the notation C[P(Ax)] as a Cox process characterized by the
rate distribution P(),). Lastly, let 2; represent the sequence of stochastic variable
A € [A,,Ai] predicted by our model, where A, and A; are stochastic variables
corresponding to the realizations of C[P(A,)] and C[P(A,)], respectively.

The stochastic process for the CTCP model is as follows:

1. Initialize the process by choosing k = s.
2. Take a realization for the value of N,.

3. Generate N, realizations for the value of A, from C[P(A,)]. This results to
a train of N, short co-timescale events.


4. Now, take a realization for the value of Nj.

s

. Generate N, realizations for the value of A; from C[P(X)]. This results to

a train of N; long co-timescale events.

6. Repeat the process from step 2 to step 5 until the appropriate size |Q;| for
Q,; is obtained.

The resulting , consists of alternating short and long timescale event trains.
Our model basically consists of four parameters: P(A,) - the rate distribution
for short timescale events, P()y) - the rate distribution for long timescale events,
P, and py - the parameter for the geometric distributions defining the number of
events contained in a train of short and long co-timescale events, respectively. In
the next section, we will be demonstrating the parameter estimation for the model.

3.2.2 Parameter Estimation

Our model’s parameters are dependent on each user. Hence, we must evaluate
{P(As), P(\)sPa Pi}: for each user i.

, where D, is the sequence of empirical inter-event time

the set of parameters
Consider D; = {Ai
At; for a given user i. The index j = 1,2,3...,N; where Nj is the number of

inter-event time contained in Dj.

We use the median 1; of D; to classify events as short or long timescale events.
We assume that the use of the median value is a reasonable estimation for the
separator of the timescales because its role in the data is to divide the upper
and the lower values of the data equally. Furthermore, we allow values that are
greater than the median to have a probabilistic chance of being identified as a
short timescale event. Now, we denote a train of short co-timescale events as T,
while a train of long co-timescale events is denoted by T}. Consider Ty = {Tim}
be the sequence of trains corresponding to the same timescale k, where k € [s, 1]
and m is the m'* co-timescale train, then, the classification of events for the m'*

co-timescale train is as follows:

if At; <p; then At; € Tam
, At; € Tom — with probability e~(4s-#)/% (3.1)
if At; > me then { At; €Tim otherwise


where 7 is defined as the characteristic timescale dispersion for user é, with the
form:

(32)

The value yj; is the median of D; and IQR; is the interquartile range of D;.

Note that in Eq. 3.1, the classification of events for Tam terminates when the
consecutive inter-event times At;, Atj1, Atj42, ... Atjin were classified to belong
to T,m and the next value Atj4n41 was classified to belong to Tim- On the other
hand, when consecutive At; were classified to belong to Tim and the next At; was
labeled as a short timescale event, the train Tim will be concluded such that this
At; will now belong to the T;m41 short co-timescale train. The entire data D; will
assume the form D; = {T3,, Ti1,Ts,2,Ti,2,---}; i-e., a sequence of alternating short
and long co-timescale trains, after the classification of events.

We will derive the distribution of rates for a user from the trains of co-timescale
events T; = {Tm}. The distribution of rates P;(Ax) for user 4 is obtained as

follows:

Ad) = {ae | Ae= ay

where (Tim) is the mean of the inter-event times At in Thm train.

for all m} (3.3)

On the other hand, the calculation for the model parameters p, and p, will be
based from the average length of trains of co-timescale events. Mathematically,

the value for py is calculated as:

m=

Lm [Tel

where [Tg| corresponds to the number of the trains in Ty while |Ti:m| corresponds
to the length of the train Tm € Tr -

We present in Fig. 3.1 a visualization of the D;, together with the co-timescale

trains after being classified. The resulting distributions for P(A.) and P(x) are

(3.4)

also shown.

Now, the values of the parameters for our model have been defined. As a
reminder, the set of parameters for user i will be denoted by 6;. In the next
section, we will be discussing the method used to optimize the set of parameters

that will characterize a user.


E 20 yer ~ Fis
g &
Ba Bos
SS ew aw ae ae toate ete ro ‘e
atts} aM

Figure 3.1: A) We present a graphical representation of a portion of a user’s time series.
Each event corresponds to the vertical lines and the distance between these events is
the inter-event time. B) We identified the events of the time series in A according to
Eq. 3.1 to produce the sequence of short co-timescale (Dark Blue) and long co-timescale
(Light Red) event trains. C) We zoomed in a portion of the sequence of co-timescale
trains to show that each of the trains consists of at least two events whose inter-event
time is co-timescale. D) The associated empirical distribution of inter-event time for
this user's time series. E-F) The empirical form of two of the model’s parameters, i.e.,
the rate distributions P(A,) and P(.,), respectively, are shown.

3.2.3. Model Parameter Optimization

Since each parameter estimation procedure is likely to produce a different set
of parameters 6;, our goal is to find the optimum parameter 6;. When we say 6,
this refers to the set of estimated parameters that conditions our model to yield
the best fit to the empirical data.

Consider all the definitions in the previous sections. We optimize the parame-
ters characterizing user i by implementing the KS test defined in Chapter 2. We
define the notation @(0;) as the model prediction given the parameters 6;. The
KS test is used to compare the predictions of our model 9; = .@(8;) against the
empirical data D;. The KS test statistic K is the quantity to be minimized such
that the set of parameters that will yield the minimum K statistic is the optimum
parameter set 6,.

In our work, we performed the optimization procedure by estimating the set
of parameters five times giving us ©; = {6;,;}, where j € [1,5]. Then, each of the


estimated parameters was used in the model to produce 9; = (0,;) that is five
times the size of the empirical data D; so that it will assume a smoother distribu-
tion. Next, we calculated the K statistic between the model predictions 9,; and
the empirical data. The set of parameters 0;,; corresponding to the minimum K
statistic is assigned as the optimum parameter 6; for the model explaining user i.

3.2.4 Quantification of Model Agreement to Empirical Data:
Calculation of p-value

In our work, we used the Monte Carlo hypothesis testing discussed in Chapter 2
to quantify the agreement of our model’s predictions against the empirical data.

As illustrated in Chapter 2, we perform the Monte Carlo hypothesis testing
by first obtaining the best parameters 6 for our model .@. Then, we evaluated
the equality of the model prediction 9 against the empirical data D using the KS
test. The K statistic obtained from this test was noted for the evaluation of the
p-value.

On the other hand, we generated an ensemble of 100 synthetic datasets D, from
our model with parameters 6. These synthetic datasets, the same as the empirical
data, were modeled using #. Therefore, we obtained the best parameters 6, for
the model of the synthetic dataset as prescribed in the previous section. Also,
we evaluated the equality of the model prediction J, against the synthetic data
D, using the KS test. The collection of K statistic for the ensemble of synthetic
dataset was stored for the calculation of the p-value.

The p-value of the model corresponding to the data D is given by Eq. 2.17.
When the resulting p-value for a user is greater than or equal to p = 0.05, then, we
accept the model as a plausible explanation for the user tweet posting behavior.
In contrast, when the p-value calculated for a user is less than p = 0.05, we

dismiss the claim that, our model is a viable one in explaining the behavior of that
particular user.

The p-value obtained for each user we will be used to analyze our results, i.e.,
the performance of the model.

3.2.5 The Null Model

We define the truncated power law as the null model for our work. All users in


the dataset will be modeled as well using the truncated power law model defined
in Chapter 2. Our purpose in defining a null model is to have a comparison or a
baseline with which the results of our model will be compared upon.

3.3 Activity Metric and the User Classes

In this section, we will be introducing the activity metric and the concept of
user classes. These concepts will be used in the analysis of the results.

3.3.1 Activity Metric

We define a metric corresponding to the total rate at which an individual posts
messages in Twitter. This metric is called the activity metric A. For each user i,
the value of the activity metric A; is given by [8]:

Ni
Te
where JN; is the total number of tweets posted by a user and 7; is the time difference

A= (35)

between the most recent tweet and the oldest tweet in the timeline.

3.3.2 User Classes

We classify users into four different user classes to have a deeper insight on
the applicability of our model across different classes of users. The classes of users
will be based from the activity metric A.

Assume that the set of the activity metric {A;} for all users has been obtained.
‘This set is then sorted in increasing value of A. We then divide the sorted set
equally into four. The subset containing the quarter of users with the lowest value
of Ais referred to as the low activity class of users. Accordingly, the next quarter
of users correspond to the mid-low activity class of users. Then, the third quarter
of the users belong to the mid-high activity class of users. Lastly, the remaining
quarter of users with the highest value for A belong to the high activity class of

users.


Chapter 4
Results and Discussion

In this chapter, we will present our results outlined as follows. First, we will
be showing the empirical probability distributions of sampled users in the dataset.
Second, we will show the results of the model for all users as summarized by the
p-value. The corresponding p-value obtained for the truncated power law will be
presented as well. Third, we will determine the behavior of the model as applied

to different classes of users.

4.1 The Empirical Cumulative Distribution of
User Inter-event Times

‘The empirical cumulative distribution, and will be referred to as the empir-
ical distribution in the rest of the discussion, of inter-event times for each user
was obtained. The empirical distribution for each user defines the probability of
occurrence of a given inter-event time At. We show the empirical distribution of
inter-event times of eight users from the Twitter dataset in Fig. 4.1.


1.0

0.8

0.6


PAX >At)


0.0

1.0 .

N= 1085 = 491
06 L 4
of
02 L
0.0 ms
1.0

N= 2049 N= 1148
ot 4
0.2
0.0
1.0 .

N = 3208 N= 3111
0.6
0.0 -

10° 10? 10' 10° 10° 10° 10? 10! 10° 10°

At At

PIX>At)

P(X>At)

P(X >At)

Figure 4.1: The sequence of plots shown in this figure are the empirical distributions
for eight users. Observe that the empirical distributions of users in the right column all
possess a step-like pattern (encircled in red). We argue that this pattern is associated
with the seasonality of user behavior. This claim is based on the fact that seasonal
events tend to introduce a bias on the value of the inter-event time associated with the
period of seasonality. This bias will introduce peaks in the probability distribution of
the inter-event time which translates to this pattern when the empirical distribution is
obtained. 26

Notice that each of the users presented show very different form for the inter-
event time empirical distribution. This is indicative of the inherent inhomogeneity
of users. Furthermore, notice the irregular patterns in the empirical distributions
in the right column of Fig. 4.1. These irregular patterns are likely to be due to
seasonality as well as sleeping patterns. This can be the case because such periodic
behavior is expected to cause a bias towards the occurrence of inter-event times
corresponding to the period of the events; hence, resulting to a relatively steep
slope in the region of these values.

4.2 Model Fitting

4.2.1 Fitting of CTCP Model to Empirical Data

In this section, the CTCP model is fitted to the empirical data. This yields
a model prediction for each user. We show in Fig. 4.2 the corresponding model
predictions to the eight users presented in Fig. 4.1.

The model predictions has an associated p-value quantifying the goodness-of-
fit of the model to the empirical data. The empirical distributions in the right
column, as pointed out in the previous section to obey seasonality, cannot be
explained by our model based on the p-value, i.e., their p-values are less than p
= 0.05 which is the threshold at which we consider the model to be a plausible
mechanism for the empirical data. On the other hand, our model is able to explain

users in the left column.


1.0

0.8

0.6

0.4

PX>At)

0.0

1.0

0.8

0.6

0.4

P(X >At)

0.2

0.0

0.66

0.30

P(X >At)

10°

Figure 4.2: Considering the users presented in Fig. 4.1, we obtained our model predic-
tions for those users. The cumulative distribution of the CTCP model prediction (red
dashed line) for each user were plotted together with the empirical distribution (black
line) of the users to graphically compare the model predictions against the empirical
data. To quantitatively assess the the goodness-of-fit of the model prediction against
the empirical data, the p-value of the fit for each user is also shown. Notice that the
users in the right column which we purportedly considered to obey seasonality are not
explained by our model, i.e., P<0.05. 9g

4.2.2 Fitting of Null Model to Empirical Data

Here we fit the truncated power law to the same set of empirical data used in
Fig. 4.1 and Fig. 4.2. Shown in Fig. 4.3 are the empirical distributions together
with the best fit truncated power law model and the p-value for each model pre-
diction.

We observe that none of the given users can be explained by the truncated
power law model because all p-values in the example are lower than p = 0.05.
Although, as will be seen in the next section, there are also users that can be

represented by the truncated power law model.

4.2.3 Section Summary

As shown in Subsection 4.2.1, the inability of the model to describe users
having seasonal behavior could be a proof that one of our hypotheses, specifically,
the statement: The deliberate removal of specific human attributes in the model
will result to the filtering out of users who are characterized by such attributes,
is correct. This allows us to suggest that our model is explaining users who
are different from users having seasonal patterns. Intuitively we would consider
seasonal signature to be present in all user sending patterns simply because we all
sleep among others, yet we observe users who do not have such signatures. In this
context, we could consider users explained by our model as deviant users.

We expect that the truncated power law will fail to model the empirical data
based on the result found in Subsection 4.2.2. The users in the right column of
Fig. 4.1 obey seasonality while those in the left column are users explained by our
model. Therefore, the truncated power law model will fail to explain them because
the underlying mechanism suggested by the truncated power law do not match
that of the mechanism which govern the set of users that were presented. With this
result, we are able to further establish the validity of our hypothesis that our model
will provide the mechanism at which deviant users perform tweet posting activity.
Since the truncated power law was not able to model the sampled users (Fig. 4.3)
and that users having seasonal behavior are left out by our model (Fig. 4.2), then,
we can deduce that are model explains users that do not obey power law behavior
as well as users that are governed by seasonality. This realization is tantamount

to the discovery of a new type individuals, i.e., neither governed by seasonality


nor by power law behavior.


P{X>At)

P(X >At)

P(X >At)

P(X >At)

en ne ee nn Od
At At

Figure 4.3: The truncated power law model (green dashed line) is fitted for eight sampled
users. We can observe that none of the users are being explained by the truncated
power law as evidenced by p-values that are less than p = 0.05. This indicates that
the mechanism governing these sampled users, whatever it may be, is not the truncated
power law.


4.3 Summary of Model Performance for All Users

We compare the performance of the two models, CTCP and truncated power
law, in describing tweet posting behavior of users in Twitter. The p-value was
used to quantify the performance of the model in explaining user behavior.

Our findings suggest that 52.08% of the Twitter users in the dataset are being
explained by our model. This finding is based on the proportion of users who have
been found to have a corresponding p-value that is greater than or equal to p =
0.05. The absolute number of user explained by our model is 73,825 from a total
of 141,754 users in the dataset. One of its implications is that this many users
have deviant behavior. Secondly, this may also address a common question in
modeling which is whether our model might have over fitted the dataset. Clearly,
this is not the case since our model did not fit all the users in the data.

On the other hand, only 10.47% of users are being explained by the truncated
power law model. This suggests that the extension of the power law mechanism
in this system yields not much insight on user sending behavior.

In Fig. 4.4 we present the cumulative distribution of the p-values for all users
for both the CTCP model as well as that of the truncated power law model.


1.0 te T T al ir
— model (CTCP)
- + truncated power law

08 F 4
Population = 141,754 ]

0.6

0.4

PX > p)

o2b 10.47%

“0.0 0.2 0.4 0.6 08 10
p-values (p)

Figure 4.4: The cumulative distribution of the calculated p-values for all users is plotted
in this figure for both the CTCP model (red solid line) and the truncated power law
model (green dashed line). The distribution of p-values for the CTCP model suggests
that more than half of the users are being explained by the model. Following our
argument, this means that almost half of the users in Twitter follow a deviant behavior.
In contrast, very few of the users are being explained by the truncated power law model.

4.4 Evaluation of the Model for Different User
Classes

We use the definition of the activity metric to classify users into four mutually
exclusive set of user classes. These classes are the following: high, mid-high,
mid-low, and low activity user class. We assessed in this section the general

performance of both models in explaining users belonging to the four classes.

4.4.1 High Activity User Class
Users whose activity metric belong to the top quarter of the population form
the high activity user class. We fitted both models of sending activity on users in

this activity class.
Our results show that for the CTCP model, 19.62% of the users in this class

are modeled by it. While, for the case of the truncated power law model, only


3.02% were explained by it.

Relative to the entire population (Fig. 4.4), the performance of our model in
describing users in this class is poorer. This same trend is observed for the case of
the truncated power law model. This implies that most users in the high activity
class are described by some other mechanism. Furthermore, this translates to the

idea that only a few of the deviant individuals are highly active.

10 T T ; i
High Activity Users
Population = 35,439
bed — model (CTCP)
- + truncated power law
& osf
a 20 20
A 3 as 15
x 10 20
 oal 5 3
as.can 0.002 04060810 0.00204060810
P Pp
02 NS 3.02%
oo Le a= tt as
00 02 08 Fr

4 06
p-values (p)

Figure 4.5: The cumulative distribution of p-values corresponding to the CTCP model
(red solid line) and the truncated power law model (green dashed line) for users in the
high activity user class. The CTCP model explains a larger portion of users in this user
class as opposed to the truncated power law model.

4.4.2 Mid-High Activity User Class

‘As opposed to the high activity user class, the CTCP model was able to explain
41.36% of the users belonging to the mid-high activity user class. On the other
hand, the proportion of users in the mid-high activity user class explained by the
truncated power law model is equal to 5.81%.

In Fig. 4.6, we show the summary of the goodness-of-fit of both models to the
empirical data for users in the mid-high activity user class as represented by the

cumulative distribution of p-values.



r T
Mid-High Activity Users
Population = 35,438

oer — model (CTCP)
- + truncated power law

P(X >p)

0.0 02 0.4 06 ~ 08 1.0
p-values (p)

Figure 4.6: The cumulative distribution of p-values corresponding to the CTCP model
(red solid line) and the truncated power law model (green dashed line) for users in the
mid-high activity user class. With the same result as in the high activity user class,
the CTCP model explains a larger portion of users in this user class as opposed to the
truncated power law model.

4.4.3 Mid-Low Activity User Class

The proportion of users in the mid-low activity user class that were successfully
explained by the CTCP model amounted to 64.80%. We observed an increasing
trend in the proportion of users that are being explained by the model as the
activity level decreases. We surmise that most deviant users are less active.

The truncated power law model was also fitted for users in the mid-low activity
user class. We found that 11.13% of the total population of the mid-low activity
user class have been explained by it. The same trend was observed as with the
CTCP model, that is, the proportion of the users explained by the truncated

power law increases as the activity level decreases.


rT T
jid-Low Activity Users
Population = 35,439

wm oo — model (cTcP)

VA + truncated power law

P(X > p)

09 02 04 06 08 20
p-values (p)

Figure 4.7: The cumulative distribution of p-values corresponding to the CTCP model
(red solid line) and the truncated power law model (green dashed line) for users in
the mid-low activity user class. We found that the CTCP model performs better in
explaining users in this class as compared with the truncated power law model.

In Fig. 4.7, the performance of the two models are presented using the cumu-

lative distribution of p-values.

4.4.4 Low Activity User Class

Finally, we have also evaluated the performance of the two models in explaining
the behavior of users in the low activity user class.

‘We found that 82.54% of the population for this class have been explained
by the CTCP model. This implies that the bulk of users that the CTCP model
explains are individuals with low activity. With this, we may infer that there

exists a correlation between the deviant behavior of users and low activity.


x T i
82.54% Low Activity Users
Population = 35,438
bead — model (CTCP)
- + truncated power law
@& osb
A
Sy
BH oat
o2f
a aa
00 02 04 08 08 Fd

p-values (p)

Figure 4.8: The cumulative distribution of p-values corresponding to the CTCP model
(red solid line) and the truncated power law model (green dashed line) for users in the
low activity user class. The CTCP model explains almost all users in this user class.
Interestingly though, is the comparatively high performance of the truncated power law
model in explaining this set of users.

The truncated power law model, on the other hand, have been able to explain

about 21.91% of users in the same class.

4.4.5 Section Summary

In this section, we have shown the behavior of both models in explaining users
belonging to different user classes based on the activity metric. We have observed
that the performance of both models are inversely related to the activity level,
ite, the proportion of users explained by the models is low when the user class
has high activity.

These observations found for the CTCP model allow us to infer that most
deviant individuals have low activity. We consider this to be expected since the
tendency of low activity users to express a prominent signature of seasonality
in Twitter is low due to their low presence. For the heavily active users, their
seasonal behavior will likely be reflected in their inter-event time distribution.
This is because, if we assume that users having high activity send messages when
in front of a computer regularly, then, when he/she is away, his/her absence will
be observed. Furthermore, when he/she is away from the computer at seasonal

or periodic time, e.g., going to school, eating, and sleeping, these periodic times


will introduce a bias on the inter-event time distribution resulting to a signature
of seasonality.

Our results might seem contradictory to the argument posed above since there
are still users with high activity that, are nevertheless explained by our model. Our
proposed explanation to this is that these users are almost always active. With
this, seasonality signature will not be present in their inter-event time distribu-
tion. Their seeming omnipresence in Twitter is attributed to the technological
revolution in the contemporary time. Now, users are able to post tweets anytime
and anywhere due to the multitude of ways that Twitter can be accessed. These
accessibility option ranges from the computer workstation (static) up to mobile
devices such as laptop, cellphones, smart phones and tablets. This flexibility in
accessing or posting tweets allows users to circumvent hindrances which lead to
seasonal signatures. We may clarify this point by an example. Note that some
time ago, users can only access online sites using a computer workstation which
is a static device. Hence, whenever they leave the computer, they can no longer
post tweets. Now, due to the availability of mobile devices capable of accessing
Twitter, their posting activity during the period of time that they are away from
their workstation is being catered by these devices.

We believe that our observations have offered a new insight on the evolution
of human behavior as affected by evolving technological factors. These results
further imply that humans will certainly evolve given some form of extra “degrees
of freedom”, wherein in this case is provided by technological improvements in

mobile devices.


Chapter 5
Summary and Conclusions

In this work we developed the Co-Timescale Cox Process (CTCP) model to
explain the tweet posting behavior of users in Twitter. Our model is based on a
new perspective of modeling wherein we did not consider a specific human behav-
ioral attribute. The CTCP model is based on the concept of co-timescale events
and Cox process. Despite not explicitly incorporating behavioral attributes in our
model, our results show, that our model provides a competent performance in ex-
plaining user behavior in Twitter. Furthermore, our model exclusively explains a
certain group of individuals who do not obey power law behavior as well as season-
ality as discussed in Subsection 4.2.3. This group of individuals can be considered
as deviant since they are individuals that cannot be explained by models which
are based on intuitive factors that affect human behavior.

Next, we have shown that our model is able to explain 52.08% of the total
users in the dataset used. This result suggests that the majority of the users in
the dataset used can be explained by our model. Furthermore, we have shown
that our proposed model is able to explain more users as compared with the null
model used - the truncated power law model. This suggests that in terms of the
mechanistic explanation, more users in the Twitter dataset obey deviant behavior
relative to users obeying a power law behavior. Note that not all users have been
explained by both models presented in this paper; hence, we may consider other
types of mechanisms that will explain the remaining number of unexplained users.
One of this possible mechanisms is the seasonality driven mechanism.

We also considered the performance of the CTCP model and the truncated
power law model in explaining user behavior based on the level of user activity.

We have defined four classes of users: the high, mid-high, mid-low and low activity


user classes. When we modeled users in these classes, we found that an inverse
relation between the model performance and the activity level exists.

In the high activity user class, we found that 19.62% of the users have been
explained by the CTCP model while 3.02% have been explained by the truncated
power law. For the case of mid-high activity user class, 41.36% and 5.81% of users
were explained by the CTCP model and the truncated power model, respectively.
The mid-low activity user class have 64.80% of its users being explained by the
CTCP model. The truncated power law, however, explained 11.13% of the users
in the mid-low activity user class, Finally, 82.54% of users in the low activity user
class were explained by the CTCP model. In contrast, the truncated power law
model have explained 21.91% of the users in the low activity user class.

New insight on human behavior have been suggested in Subsection 4.4.5. We
discussed that the perceived deviant behavior of users in Twitter which is being ex-
plained by our model can be attributed to technological innovations. We suggested
that the seeming omnipresence of deviant user as characterized by the user’s lack
of seasonal signatures may be due to the many ways that a user can access Twit-
ter. This is brought by the technological innovations in mobile communication

allowing users to post tweets almost anytime.


Ss

{10

(uy

Bibliography

J. G. Oliveira and A.-L. Barabési, “Human dynamics: Darwin and Einstein
correspondence patterns.,” Nature, vol. 437, p. 1251, Oct. 2005.

Y. Wu, C. Zhou, J. Xiao, J. Kurths, and H. J. Schelinhuber, “Evidence for a
bimodal distribution in human communication.,” Proceedings of the National
Academy of Sciences of the United States of America, vol. 107, pp. 1803-8,
Nov. 2010.

H. Wei, H. Xiao-Pu, Z. Tao, and W. Bing-Hong, “Heavy-Tailed Statistics in
Short-Message Communication.,” Chinese Physics Letters, vol. 26, p. 028902,
Feb. 2009.

N.-N. Li, N. Zhang, and T. Zhou, “Empirical analysis on temporal statistics
of human correspondence patterns.,” Physica A: Statistical Mechanics and its
Applications, vol. 387, pp. 6391-6394, Nov. 2008.

A.-L. Barabési, “The origin of bursts and heavy tails in human dynamics.,”
Nature, vol. 435, pp. 207-11, May 2005.

A. Vazquez, J. Oliveira, Z. Dezsd, K.-I. Goh, I. Kondor, and A.-L. Barabési,
“Modeling bursts and heavy tails in human dynamics..” Physical Review E,
vol. 73, pp. 1-19, Mar. 2006,

P. Wang, T. Zhou, X.-P. Han, and B.-H. Wang, “Modeling correlated human
dynamics.,” arXiv, pp. 1-7, July 2010. http://arxiv.org/abs/1007.4440.

Z.-D. Zhao and T. Zhou, “Empirical analysis of online human dynamics.,”
Physica A: Statistical Mechanics and its Applications, vol. 391, pp. 3308-3315,
June 2012.

U. Harder and M. Paczuski, “Correlated dynamics in human printing behav-
ior.,” arXiv, p. 4, Dec. 2004, http: //arxiv.org/abs/cs/0412027.

R. D. Malmgren, D. B. Stouffer, A. E. Motter, and L. A. N. Amaral, “A
Poissonian explanation for heavy tails in e-mail communication.,” Proceedings
of the National Academy of Sciences of the United States of America, vol. 105,
pp. 18153-8, Nov. 2008.

X.-P. Han, T. Zhou, and B.-H. Wang, “Modeling human dynamics with adap-
tive interest.,” New Journal of Physics, vol. 10, p. 073010, July 2008.



13)
15)


17,

18)

19]

[20]

[21]

[22)

[23]

[24]

25]

26]

[27]

(28)

S, Ming-Sheng, C. Guan-Xiong, D. Shuang-Xing, W. Bing-Hong, and Z. Tao,
“Interest-Driven Model for Human Dynamics.,” Chinese Physics Lelters,
vol. 27, p. 048701, Apr. 2010.

“Twitter.,” Last Accessed: Feb. 11, 2013. http://www.twitter.com/.
“Twitter APL,” Last Accessed: Feb. 11, 2013. http://dev.twitter.com/.

A. Hayter, Introduction to Probability and Statistics for Engineers and Sci-
entists. Boston: Brooks/Cole, Cengage Learning, 4th ed., 2012.

D. Zwillinger, CRC Standard Mathematical Tables and Formulae. New York:
Chapman & Hall/CRC, 3ist ed., 2003.

A. Clauset, C. R. Shalizi, and M. E. J. Newman, “Power-Law Distributions
in Empirical Data.,” SIAM Review, vol. 51, pp. 661-703, Nov. 2009.

M. Newman, “Scientific collaboration networks. I. Network construction and
fundamental results.,” Physical Review EF, vol. 64, p. 016131, June 2001.

H.-S. Niwa, “Power-law versus exponential distributions of animal group
sizes..” arXiv, p. 19, May 2003. http://arxiv.org/abs/cond-mat/0305241.

L. A. Amaral, A. Scala, M. Barthelemy, and H. E. Stanley, “Classes of small-
world networks.,” Proceedings of the National Academy of Sciences of the
United States of America, vol. 97, pp. 11149-52, Oct. 2000.

C. Zhou, L. Zemanové, G. Zamora, C. Hilgetag, and J. Kurths, “Hierar-
chical Organization Unveiled by Functional Connectivity in Complex Brain
Networks.,” Physical Review Letters, vol. 97, p. 238103, Dec. 2006.

I. J. Gomez Portillo and P. M. Gleiser, “An adaptive complex network model
for brain functional networks.,” PloS one, vol. 4, p. e6863, Jan. 2009.

McGraw-Hill Science and Technology Dictionary, “Empirical Data.,” Last
Accessed: Feb. 11, 2013. http://www.answers.com/topic/empirical-evidence.

McGraw-Hill Science and Technology Dictionary, “Synthetic Data.,” Last
Accessed: Feb. 11, 2013. http://www.answers.com/topic/synthetic-data.

M. S. Bartlett, “The Spectral Analysis of Point Process.,” Journal of the
Royal Statistical Society, vol. 25, no. 2, pp. 264-296, 1963.

D. J. Daley and D. Vere-Jones, An introduction to the theory of point pro-
cesses, {V}ol. {I}. Probability and its Applications (New York), New York:
Springer, second ed., 2008.

D. R. Cox, “Some Statistical Methods Connected with Series of Events.,”
Journal of the Royal Statistical Society, vol. 17, pp. 129-164, Jan. 1955.

F. J. Massey, “The Kolmogorov-Smirnov Test for Goodness of Fit.,” Journal
of the American Statistical Association, vol. 46, pp. 68-78, Mar. 1951.


[29] G. Gigerenzer, “Mindless statistics.,” The Journal of Socio-Economics,
vol. 33, pp. 587-606, Nov. 2004.

[30] L. A. Waller, D. Smith, J. E. Childs, and L. A. Real, “Monte Carlo assess-

ments of goodness-of-fit for ecological simulation models.,” Ecological Mod-
elling, vol. 164, pp. 49-63, June 2003.


